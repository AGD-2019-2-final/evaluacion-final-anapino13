{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bigdata extension is already loaded. To reload it, use:\n",
      "  %reload_ext bigdata\n"
     ]
    }
   ],
   "source": [
    "%load_ext bigdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pig_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeout 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fs -rm output/*\n",
      "2020-02-10 00:11:49,005 [main] WARN  org.apache.hadoop.ipc.Client - Failed to connect to server: 0.0.0.0/0.0.0.0:9000: try once and fail.\n",
      "java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1381)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1345)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)\n",
      "\tat com.sun.proxy.$Proxy10.getListing(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getListing(ClientNamenodeProtocolTranslatorPB.java:597)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)\n",
      "\tat com.sun.proxy.$Proxy11.getListing(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1630)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1614)\n",
      "\tat org.apache.hadoop.hdfs.DistributedFileSystem.listStatusInternal(DistributedFileSystem.java:900)\n",
      "\tat org.apache.hadoop.hdfs.DistributedFileSystem.access$600(DistributedFileSystem.java:114)\n",
      "\tat org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:964)\n",
      "\tat org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:961)\n",
      "\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n",
      "\tat org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(DistributedFileSystem.java:961)\n",
      "\tat org.apache.hadoop.fs.Globber.listStatus(Globber.java:76)\n",
      "\tat org.apache.hadoop.fs.Globber.doGlob(Globber.java:234)\n",
      "\tat org.apache.hadoop.fs.Globber.glob(Globber.java:148)\n",
      "\tat org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1686)\n",
      "\tat org.apache.hadoop.fs.shell.PathData.expandAsGlob(PathData.java:326)\n",
      "\tat org.apache.hadoop.fs.shell.Command.expandArgument(Command.java:245)\n",
      "\tat org.apache.hadoop.fs.shell.Delete$Rm.expandArgument(Delete.java:93)\n",
      "\tat org.apache.hadoop.fs.shell.Command.expandArguments(Command.java:228)\n",
      "\tat org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:103)\n",
      "\tat org.apache.hadoop.fs.shell.Command.run(Command.java:175)\n",
      "\tat org.apache.hadoop.fs.FsShell.run(FsShell.java:317)\n",
      "\tat org.apache.pig.tools.grunt.GruntParser.processFsCommand(GruntParser.java:1173)\n",
      "\tat org.apache.pig.tools.pigscript.parser.PigScriptParser.parse(PigScriptParser.java:136)\n",
      "\tat org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:230)\n",
      "\tat org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:205)\n",
      "\tat org.apache.pig.tools.grunt.Grunt.run(Grunt.java:66)\n",
      "\tat org.apache.pig.Main.run(Main.java:564)\n",
      "\tat org.apache.pig.Main.main(Main.java:175)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.util.RunJar.run(RunJar.java:239)\n",
      "\tat org.apache.hadoop.util.RunJar.main(RunJar.java:153)\n",
      "rm: Call From 197c06016758/172.17.0.2 to 0.0.0.0:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      " fs -rmdir  output\n",
      "2020-02-10 00:11:49,139 [main] WARN  org.apache.hadoop.ipc.Client - Failed to connect to server: 0.0.0.0/0.0.0.0:9000: try once and fail.\n",
      "java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1381)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1345)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)\n",
      "\tat com.sun.proxy.$Proxy10.getFileInfo(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:796)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)\n",
      "\tat com.sun.proxy.$Proxy11.getFileInfo(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1649)\n",
      "\tat org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1440)\n",
      "\tat org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1437)\n",
      "\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n",
      "\tat org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1437)\n",
      "\tat org.apache.hadoop.fs.Globber.getFileStatus(Globber.java:64)\n",
      "\tat org.apache.hadoop.fs.Globber.doGlob(Globber.java:269)\n",
      "\tat org.apache.hadoop.fs.Globber.glob(Globber.java:148)\n",
      "\tat org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1686)\n",
      "\tat org.apache.hadoop.fs.shell.PathData.expandAsGlob(PathData.java:326)\n",
      "\tat org.apache.hadoop.fs.shell.Command.expandArgument(Command.java:245)\n",
      "\tat org.apache.hadoop.fs.shell.Command.expandArguments(Command.java:228)\n",
      "\tat org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:103)\n",
      "\tat org.apache.hadoop.fs.shell.Command.run(Command.java:175)\n",
      "\tat org.apache.hadoop.fs.FsShell.run(FsShell.java:317)\n",
      "\tat org.apache.pig.tools.grunt.GruntParser.processFsCommand(GruntParser.java:1173)\n",
      "\tat org.apache.pig.tools.pigscript.parser.PigScriptParser.parse(PigScriptParser.java:136)\n",
      "\tat org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:230)\n",
      "\tat org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:205)\n",
      "\tat org.apache.pig.tools.grunt.Grunt.run(Grunt.java:66)\n",
      "\tat org.apache.pig.Main.run(Main.java:564)\n",
      "\tat org.apache.pig.Main.main(Main.java:175)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.util.RunJar.run(RunJar.java:239)\n",
      "\tat org.apache.hadoop.util.RunJar.main(RunJar.java:153)\n",
      "rmdir: Call From 197c06016758/172.17.0.2 to 0.0.0.0:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      " fs -rm -f -r data.tsv\n",
      "2020-02-10 00:11:49,210 [main] WARN  org.apache.hadoop.ipc.Client - Failed to connect to server: 0.0.0.0/0.0.0.0:9000: try once and fail.\n",
      "java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1381)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1345)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)\n",
      "\tat com.sun.proxy.$Proxy10.getFileInfo(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:796)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)\n",
      "\tat com.sun.proxy.$Proxy11.getFileInfo(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1649)\n",
      "\tat org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1440)\n",
      "\tat org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1437)\n",
      "\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n",
      "\tat org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1437)\n",
      "\tat org.apache.hadoop.fs.Globber.getFileStatus(Globber.java:64)\n",
      "\tat org.apache.hadoop.fs.Globber.doGlob(Globber.java:269)\n",
      "\tat org.apache.hadoop.fs.Globber.glob(Globber.java:148)\n",
      "\tat org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1686)\n",
      "\tat org.apache.hadoop.fs.shell.PathData.expandAsGlob(PathData.java:326)\n",
      "\tat org.apache.hadoop.fs.shell.Command.expandArgument(Command.java:245)\n",
      "\tat org.apache.hadoop.fs.shell.Delete$Rm.expandArgument(Delete.java:93)\n",
      "\tat org.apache.hadoop.fs.shell.Command.expandArguments(Command.java:228)\n",
      "\tat org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:103)\n",
      "\tat org.apache.hadoop.fs.shell.Command.run(Command.java:175)\n",
      "\tat org.apache.hadoop.fs.FsShell.run(FsShell.java:317)\n",
      "\tat org.apache.pig.tools.grunt.GruntParser.processFsCommand(GruntParser.java:1173)\n",
      "\tat org.apache.pig.tools.pigscript.parser.PigScriptParser.parse(PigScriptParser.java:136)\n",
      "\tat org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:230)\n",
      "\tat org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:205)\n",
      "\tat org.apache.pig.tools.grunt.Grunt.run(Grunt.java:66)\n",
      "\tat org.apache.pig.Main.run(Main.java:564)\n",
      "\tat org.apache.pig.Main.main(Main.java:175)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.util.RunJar.run(RunJar.java:239)\n",
      "\tat org.apache.hadoop.util.RunJar.main(RunJar.java:153)\n",
      "rm: Call From 197c06016758/172.17.0.2 to 0.0.0.0:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      " fs -put data.tsv\n",
      "2020-02-10 00:11:49,282 [main] WARN  org.apache.hadoop.ipc.Client - Failed to connect to server: 0.0.0.0/0.0.0.0:9000: try once and fail.\n",
      "java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1381)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1345)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)\n",
      "\tat com.sun.proxy.$Proxy10.getFileInfo(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:796)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)\n",
      "\tat com.sun.proxy.$Proxy11.getFileInfo(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1649)\n",
      "\tat org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1440)\n",
      "\tat org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1437)\n",
      "\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n",
      "\tat org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1437)\n",
      "\tat org.apache.hadoop.fs.shell.PathData.lookupStat(PathData.java:172)\n",
      "\tat org.apache.hadoop.fs.shell.PathData.<init>(PathData.java:104)\n",
      "\tat org.apache.hadoop.fs.shell.PathData.<init>(PathData.java:81)\n",
      "\tat org.apache.hadoop.fs.shell.CommandWithDestination.getRemoteDestination(CommandWithDestination.java:191)\n",
      "\tat org.apache.hadoop.fs.shell.CopyCommands$Put.processOptions(CopyCommands.java:256)\n",
      "\tat org.apache.hadoop.fs.shell.Command.run(Command.java:174)\n",
      "\tat org.apache.hadoop.fs.FsShell.run(FsShell.java:317)\n",
      "\tat org.apache.pig.tools.grunt.GruntParser.processFsCommand(GruntParser.java:1173)\n",
      "\tat org.apache.pig.tools.pigscript.parser.PigScriptParser.parse(PigScriptParser.java:136)\n",
      "\tat org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:230)\n",
      "\tat org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:205)\n",
      "\tat org.apache.pig.tools.grunt.Grunt.run(Grunt.java:66)\n",
      "\tat org.apache.pig.Main.run(Main.java:564)\n",
      "\tat org.apache.pig.Main.main(Main.java:175)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.util.RunJar.run(RunJar.java:239)\n",
      "\tat org.apache.hadoop.util.RunJar.main(RunJar.java:153)\n",
      "put: Call From 197c06016758/172.17.0.2 to 0.0.0.0:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      " u = LOAD 'data.tsv' USING PigStorage('\\t') \n",
      "    AS (letra:CHARARRAY, \n",
      "        bolsa:bag{(a:CHARARRAY)},\n",
      "        mapa:map[]);\n",
      "2020-02-10 00:11:50,322 [main] WARN  org.apache.hadoop.ipc.Client - Failed to connect to server: 0.0.0.0/0.0.0.0:9000: try once and fail.\n",
      "java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1381)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1345)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)\n",
      "\tat com.sun.proxy.$Proxy10.getFileInfo(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:796)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)\n",
      "\tat com.sun.proxy.$Proxy11.getFileInfo(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1649)\n",
      "\tat org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1440)\n",
      "\tat org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1437)\n",
      "\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n",
      "\tat org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1437)\n",
      "\tat org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1437)\n",
      "\tat org.apache.pig.backend.hadoop.datastorage.HDataStorage.isContainer(HDataStorage.java:216)\n",
      "\tat org.apache.pig.backend.hadoop.datastorage.HDataStorage.asElement(HDataStorage.java:132)\n",
      "\tat org.apache.pig.backend.hadoop.datastorage.HDataStorage.asElement(HDataStorage.java:143)\n",
      "\tat org.apache.pig.parser.QueryParserUtils.getCurrentDir(QueryParserUtils.java:93)\n",
      "\tat org.apache.pig.parser.LogicalPlanBuilder.buildLoadOp(LogicalPlanBuilder.java:896)\n",
      "\tat org.apache.pig.parser.LogicalPlanGenerator.load_clause(LogicalPlanGenerator.java:3568)\n",
      "\tat org.apache.pig.parser.LogicalPlanGenerator.op_clause(LogicalPlanGenerator.java:1625)\n",
      "\tat org.apache.pig.parser.LogicalPlanGenerator.general_statement(LogicalPlanGenerator.java:1102)\n",
      "\tat org.apache.pig.parser.LogicalPlanGenerator.statement(LogicalPlanGenerator.java:560)\n",
      "\tat org.apache.pig.parser.LogicalPlanGenerator.query(LogicalPlanGenerator.java:421)\n",
      "\tat org.apache.pig.parser.QueryParserDriver.parse(QueryParserDriver.java:191)\n",
      "\tat org.apache.pig.PigServer$Graph.validateQuery(PigServer.java:1792)\n",
      "\tat org.apache.pig.PigServer$Graph.registerQuery(PigServer.java:1765)\n",
      "\tat org.apache.pig.PigServer.registerQuery(PigServer.java:708)\n",
      "\tat org.apache.pig.tools.grunt.GruntParser.processPig(GruntParser.java:1110)\n",
      "\tat org.apache.pig.tools.pigscript.parser.PigScriptParser.parse(PigScriptParser.java:512)\n",
      "\tat org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:230)\n",
      "\tat org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:205)\n",
      "\tat org.apache.pig.tools.grunt.Grunt.run(Grunt.java:66)\n",
      "\tat org.apache.pig.Main.run(Main.java:564)\n",
      "\tat org.apache.pig.Main.main(Main.java:175)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.util.RunJar.run(RunJar.java:239)\n",
      "\tat org.apache.hadoop.util.RunJar.main(RunJar.java:153)\n",
      "2020-02-10 00:11:50,329 [main] ERROR org.apache.pig.tools.grunt.Grunt - ERROR 6007: Unable to check name hdfs://0.0.0.0:9000/user/root\n",
      "Details at logfile: /datalake/evaluacion-final-anapino13-master/02-pig-50/q06-10/pig_1581293503711.log\n",
      " dato1= FOREACH u GENERATE FLATTEN(mapa) as clave;\n",
      "2020-02-10 00:11:50,435 [main] ERROR org.apache.pig.tools.grunt.Grunt - ERROR 1200: Pig script failed to parse: <line 1, column 15> Undefined alias: u\n",
      "Details at logfile: /datalake/evaluacion-final-anapino13-master/02-pig-50/q06-10/pig_1581293503711.log\n",
      " dato2= group dato1 by clave;\n",
      "2020-02-10 00:11:50,522 [main] ERROR org.apache.pig.tools.grunt.Grunt - ERROR 1200: Pig script failed to parse: <line 1, column 13> Undefined alias: dato1\n",
      "Details at logfile: /datalake/evaluacion-final-anapino13-master/02-pig-50/q06-10/pig_1581293503711.log\n",
      " dato3 = FOREACH dato2 GENERATE group, COUNT(dato1);\n",
      "2020-02-10 00:11:50,594 [main] ERROR org.apache.pig.tools.grunt.Grunt - ERROR 1200: Pig script failed to parse: <line 1, column 16> Undefined alias: dato2\n",
      "Details at logfile: /datalake/evaluacion-final-anapino13-master/02-pig-50/q06-10/pig_1581293503711.log\n",
      " store dato3 into 'output' using PigStorage(',');\n",
      "2020-02-10 00:11:50,676 [main] ERROR org.apache.pig.tools.grunt.Grunt - ERROR 1200: Pig script failed to parse: <line 1, column 6> Undefined alias: dato3\n",
      "Details at logfile: /datalake/evaluacion-final-anapino13-master/02-pig-50/q06-10/pig_1581293503711.log\n",
      " fs -copyToLocal output\n",
      "2020-02-10 00:11:50,760 [main] WARN  org.apache.hadoop.ipc.Client - Failed to connect to server: 0.0.0.0/0.0.0.0:9000: try once and fail.\n",
      "java.net.ConnectException: Connection refused\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)\n",
      "\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:685)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:788)\n",
      "\tat org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)\n",
      "\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1381)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1345)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)\n",
      "\tat com.sun.proxy.$Proxy10.getFileInfo(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:796)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)\n",
      "\tat com.sun.proxy.$Proxy11.getFileInfo(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1649)\n",
      "\tat org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1440)\n",
      "\tat org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1437)\n",
      "\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n",
      "\tat org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1437)\n",
      "\tat org.apache.hadoop.fs.Globber.getFileStatus(Globber.java:64)\n",
      "\tat org.apache.hadoop.fs.Globber.doGlob(Globber.java:269)\n",
      "\tat org.apache.hadoop.fs.Globber.glob(Globber.java:148)\n",
      "\tat org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1686)\n",
      "\tat org.apache.hadoop.fs.shell.PathData.expandAsGlob(PathData.java:326)\n",
      "\tat org.apache.hadoop.fs.shell.Command.expandArgument(Command.java:245)\n",
      "\tat org.apache.hadoop.fs.shell.Command.expandArguments(Command.java:228)\n",
      "\tat org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:103)\n",
      "\tat org.apache.hadoop.fs.shell.Command.run(Command.java:175)\n",
      "\tat org.apache.hadoop.fs.FsShell.run(FsShell.java:317)\n",
      "\tat org.apache.pig.tools.grunt.GruntParser.processFsCommand(GruntParser.java:1173)\n",
      "\tat org.apache.pig.tools.pigscript.parser.PigScriptParser.parse(PigScriptParser.java:136)\n",
      "\tat org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:230)\n",
      "\tat org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:205)\n",
      "\tat org.apache.pig.tools.grunt.Grunt.run(Grunt.java:66)\n",
      "\tat org.apache.pig.Main.run(Main.java:564)\n",
      "\tat org.apache.pig.Main.main(Main.java:175)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.util.RunJar.run(RunJar.java:239)\n",
      "\tat org.apache.hadoop.util.RunJar.main(RunJar.java:153)\n",
      "copyToLocal: Call From 197c06016758/172.17.0.2 to 0.0.0.0:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "fs -rm output/*\n",
    "fs -rmdir  output\n",
    "fs -rm -f -r data.tsv\n",
    "fs -put data.tsv\n",
    "\n",
    "u = LOAD 'data.tsv' USING PigStorage('\\t') \n",
    "    AS (letra:CHARARRAY, \n",
    "        bolsa:bag{(a:CHARARRAY)},\n",
    "        mapa:map[]);\n",
    "\n",
    "\n",
    "dato1= FOREACH u GENERATE FLATTEN(mapa) as clave;\n",
    "dato2= group dato1 by clave;\n",
    "dato3 = FOREACH dato2 GENERATE group, COUNT(dato1);\n",
    "\n",
    "\n",
    "store dato3 into 'output' using PigStorage(',');\n",
    "fs -copyToLocal output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
